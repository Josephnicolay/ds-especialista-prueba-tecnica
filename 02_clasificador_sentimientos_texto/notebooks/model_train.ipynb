{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "154096c0",
   "metadata": {},
   "source": [
    "# Model training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9cdf2664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchinfo import summary\n",
    "import torchmetrics as tm\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import Word2Vec\n",
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "570909a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "12.1\n",
      "True\n",
      "NVIDIA GeForce MX350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ced02f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"../data\")\n",
    "file_path = DATA_PATH / \"processed/cleaned_sentiment_data.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "16c350e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>teenager martha moxley maggie grace move high ...</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok really like kris kristofferson usual easy g...</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spoiler read think watching movie although wou...</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi people seen wonderful movie im sure thet wo...</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recently bought dvd forgetting much hated movi...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49577</th>\n",
       "      <td>ok let start best building although hard belie...</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49578</th>\n",
       "      <td>british heritage film industry control nothing...</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49579</th>\n",
       "      <td>even know begin one family worst line dialogue...</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49580</th>\n",
       "      <td>richard tyler little boy scared everything lik...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49581</th>\n",
       "      <td>waited long watch movie also like bruce willis...</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49582 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          cleaned_review  sentiment  \\\n",
       "0      teenager martha moxley maggie grace move high ...          1   \n",
       "1      ok really like kris kristofferson usual easy g...          0   \n",
       "2      spoiler read think watching movie although wou...          0   \n",
       "3      hi people seen wonderful movie im sure thet wo...          1   \n",
       "4      recently bought dvd forgetting much hated movi...          0   \n",
       "...                                                  ...        ...   \n",
       "49577  ok let start best building although hard belie...          0   \n",
       "49578  british heritage film industry control nothing...          0   \n",
       "49579  even know begin one family worst line dialogue...          0   \n",
       "49580  richard tyler little boy scared everything lik...          0   \n",
       "49581  waited long watch movie also like bruce willis...          1   \n",
       "\n",
       "       review_length  \n",
       "0                125  \n",
       "1                111  \n",
       "2                147  \n",
       "3                 36  \n",
       "4                 61  \n",
       "...              ...  \n",
       "49577            110  \n",
       "49578            147  \n",
       "49579             65  \n",
       "49580             50  \n",
       "49581             22  \n",
       "\n",
       "[49582 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cbc46186",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df['review_length'] < 3) & ~(df['review_length'] > 180)] #Por temas de memoria durante el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "97b422c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8  # smaller batch to stay within 2GB GPUs\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, sents, labels):\n",
    "        self.sents = sents\n",
    "\n",
    "        self.PAD_TOKEN = \"<PAD>\"\n",
    "        self.UNK_TOKEN = \"<UNK>\"\n",
    "        self.PAD_IDX = 0\n",
    "        self.UNK_IDX = 1\n",
    "\n",
    "        self.vocab, self.index_word = self.get_vocab(self.sents)\n",
    "\n",
    "        self.label_mapping = {value: key for key, value in enumerate(np.unique(labels))}\n",
    "        self.labels = [self.label_mapping[l] for l in labels]\n",
    "\n",
    "    def get_vocab(self, sents):\n",
    "        tokenized_sents = list(map(lambda x: simple_preprocess(x), list(sents)))\n",
    "        corpus = [token for s in tokenized_sents for token in s]\n",
    "\n",
    "        word_count = Counter(corpus)\n",
    "        common_words = word_count.most_common()\n",
    "\n",
    "        vocab = {self.PAD_TOKEN: self.PAD_IDX, self.UNK_TOKEN: self.UNK_IDX}\n",
    "\n",
    "        for token, _ in common_words:\n",
    "            if token not in vocab:\n",
    "                vocab[token] = len(vocab)\n",
    "\n",
    "        index_to_vocab = dict(zip(vocab.values(), vocab.keys()))\n",
    "\n",
    "        return vocab, index_to_vocab\n",
    "\n",
    "    def vocab_size(self):\n",
    "        return len(self.vocab)\n",
    "\n",
    "    def vectorize(self, sent):\n",
    "        tokens = simple_preprocess(sent)\n",
    "        return [self.vocab.get(token, self.UNK_IDX) for token in tokens]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = self.vectorize(self.sents[idx])\n",
    "        input_ids = torch.tensor(input_ids)\n",
    "\n",
    "        label = torch.tensor(self.labels[idx])\n",
    "\n",
    "        return input_ids, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "99c0fed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = CustomDataset(\n",
    "    sents = df['cleaned_review'].tolist(),\n",
    "    labels = df['sentiment'].tolist()\n",
    ")\n",
    "\n",
    "\n",
    "train_size = round(0.8 * ds.__len__()) \n",
    "val_size = round(0.2 * ds.__len__())\n",
    "\n",
    "train_set , val_set = random_split(ds , [train_size , val_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "26b2c1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of the dataset is : 41295\n",
      "The size of the training set is : 33036\n",
      "The size of the validation set is : 8259\n"
     ]
    }
   ],
   "source": [
    "print(f\"the size of the dataset is : {ds.__len__()}\")\n",
    "print(f\"The size of the training set is : {train_size}\")\n",
    "print(f\"The size of the validation set is : {val_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "de5428a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def COLLATE_FN(batch):\n",
    "    inputs , labels = zip(*batch)\n",
    "\n",
    "    padded_inputs = pad_sequence(inputs, batch_first=True, padding_value=0)\n",
    "    labels = torch.stack(labels)\n",
    "\n",
    "    return padded_inputs, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6af14763",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_kwargs = {\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"pin_memory\": device == \"cuda\",\n",
    "    \"num_workers\": 0,\n",
    "    \"collate_fn\": COLLATE_FN,\n",
    "}\n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_ds = DataLoader(\n",
    "    train_set,\n",
    "    shuffle=True,\n",
    "    **loader_kwargs,\n",
    ")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "val_ds = DataLoader(\n",
    "    val_set,\n",
    "    shuffle=False,\n",
    "    **loader_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bffcbd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 256\n",
    "\n",
    "word2vec_data = list(map(lambda x: simple_preprocess(x), df['cleaned_review'].tolist()))\n",
    "\n",
    "word2vec = Word2Vec(\n",
    "    sentences=word2vec_data,\n",
    "    window=10,\n",
    "    min_count=1,\n",
    "    vector_size=EMBEDDING_DIM,\n",
    "    workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fdb4f0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = ds.vocab_size()\n",
    "word2vec_embedding_matrix = np.zeros((VOCAB_SIZE , EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9e45ba3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_embedding_matrix = torch.from_numpy(word2vec_embedding_matrix).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6f69d4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module) : \n",
    "    def __init__(\n",
    "        self , \n",
    "        vocab_size , \n",
    "        embedding_dim , \n",
    "        hidden_dim , \n",
    "        num_layers , \n",
    "        fc_dim , \n",
    "        n_classes , \n",
    "        bidirectional = False , \n",
    "        dropout_rate = None\n",
    "    ) : \n",
    "        super(LSTM , self).__init__() \n",
    "\n",
    "        self.embedding = nn.Embedding.from_pretrained(\n",
    "            pretrained_embedding_matrix , \n",
    "            padding_idx = 0 , \n",
    "            freeze = True\n",
    "        )\n",
    "\n",
    "        self.num_directional = 2 if bidirectional else 1\n",
    "        self.n_layers = num_layers \n",
    "        self.h_dim = hidden_dim\n",
    "\n",
    "        self.lstm1 = nn.LSTM(\n",
    "            embedding_dim , \n",
    "            hidden_dim , \n",
    "            num_layers , \n",
    "            dropout = dropout_rate , \n",
    "            bidirectional = bidirectional , \n",
    "            batch_first = True \n",
    "        )\n",
    "\n",
    "        self.lstm2 = nn.LSTM(\n",
    "            hidden_dim * self.num_directional , \n",
    "            hidden_dim // 2 , \n",
    "            num_layers , \n",
    "            dropout = dropout_rate , \n",
    "            bidirectional = bidirectional , \n",
    "            batch_first = True \n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc1 = nn.Linear((hidden_dim // 2) * self.num_directional , fc_dim)\n",
    "        self.fc2 = nn.Linear(fc_dim , n_classes)\n",
    "\n",
    "    def forward(self , x) : \n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        embed = self.embedding(x) #[batch_size,seq_len,embedding_dim]\n",
    "        \n",
    "        out , _ = self.lstm1(embed , None) #[batch_size,seq_len,n_directional*h_dim]\n",
    "        \n",
    "        _ , (hn , _) = self.lstm2(out ,None) #[n_directional*n_layers,batch_size,h_dim]\n",
    "\n",
    "        # We concatenate the final forward state [-2] and final backward state [-1] of the LAST layer (Layer 2)\n",
    "        hn = torch.cat((hn[-2, :, :], hn[-1, :, :]), dim=1)\n",
    "\n",
    "        fc_out = nn.functional.relu(self.fc1(hn))\n",
    "        fc_out = self.dropout(fc_out)\n",
    "        logits = self.fc2(fc_out)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "31f245e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 256\n",
    "NUM_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT_RATE = 0.5\n",
    "FC_DIM = 64\n",
    "N_CLASSES = len(np.unique(df['sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e77795aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "True\n",
      "NVIDIA GeForce MX350\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a796e808",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = LSTM(\n",
    "    vocab_size = VOCAB_SIZE , \n",
    "    embedding_dim = EMBEDDING_DIM , \n",
    "    hidden_dim = HIDDEN_DIM , \n",
    "    num_layers = NUM_LAYERS , \n",
    "    fc_dim = FC_DIM , \n",
    "    n_classes = N_CLASSES , \n",
    "    bidirectional = BIDIRECTIONAL , \n",
    "    dropout_rate = DROPOUT_RATE\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c13606aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LSTM                                     [8, 2]                    --\n",
       "├─Embedding: 1-1                         [8, 148, 256]             (18,083,840)\n",
       "├─LSTM: 1-2                              [8, 148, 512]             2,629,632\n",
       "├─LSTM: 1-3                              [8, 148, 256]             1,052,672\n",
       "├─Linear: 1-4                            [8, 64]                   16,448\n",
       "├─Dropout: 1-5                           [8, 64]                   --\n",
       "├─Linear: 1-6                            [8, 2]                    130\n",
       "==========================================================================================\n",
       "Total params: 21,782,722\n",
       "Trainable params: 3,698,882\n",
       "Non-trainable params: 18,083,840\n",
       "Total mult-adds (Units.GIGABYTES): 4.50\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 9.70\n",
       "Params size (MB): 87.13\n",
       "Estimated Total Size (MB): 96.84\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(BATCH_SIZE, 148), dtypes=[torch.long])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "75837c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def accuracy_fn(y_pred , y_true) : \n",
    "    correct = torch.eq(y_true , y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100 \n",
    "\n",
    "    return acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "593a3a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationMetrics : \n",
    "    def __init__(self , n_classes) : \n",
    "        self.metrics = {\n",
    "            'accuracy' : tm.Accuracy(\n",
    "                task = \"multiclass\" , \n",
    "                num_classes = N_CLASSES , \n",
    "                average = \"macro\"\n",
    "            ) ,\n",
    "    \n",
    "            'precision' : tm.Precision(\n",
    "                task = \"multiclass\" , \n",
    "                num_classes = N_CLASSES , \n",
    "                average = \"macro\"\n",
    "            ) ,\n",
    "    \n",
    "            'recall' : tm.Recall(\n",
    "                task = \"multiclass\" , \n",
    "                num_classes = N_CLASSES , \n",
    "                average = \"macro\"\n",
    "            ) ,\n",
    "    \n",
    "            'f1' : tm.F1Score(\n",
    "                task = \"multiclass\" , \n",
    "                num_classes = N_CLASSES , \n",
    "                average = \"macro\"\n",
    "            ) \n",
    "        }\n",
    "\n",
    "        for metric in self.metrics.values() : \n",
    "            metric.to(device)\n",
    "\n",
    "    def update(self , y_preds , y_true) : \n",
    "        for metric in self.metrics.values() : \n",
    "            metric.update(y_preds , y_true)\n",
    "\n",
    "    def compute(self) : \n",
    "        return {name : metric.compute().item() for name , metric in self.metrics.items()}\n",
    "\n",
    "    def reset(self) : \n",
    "        for metric in self.metrics.values() : \n",
    "            metric.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "05d59a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConfMatPlot(cm , confmat) :     \n",
    "    fig, ax = cm.plot()\n",
    "    ax.set_title(\"Validation Confusion Matrix\" , fontsize = 15 , fontweight = \"bold\")\n",
    "    ax.set_xlabel(\"Predicted\", fontsize=10, fontweight=\"bold\")\n",
    "    ax.set_ylabel(\"True\", fontsize=10, fontweight=\"bold\")\n",
    "\n",
    "    ax.set_xticks(np.arange(len(label_map)))\n",
    "    ax.set_xticklabels(list(label_map.values()), rotation=45, ha='right', fontsize=8)\n",
    "    ax.set_yticks(np.arange(len(label_map)))\n",
    "    ax.set_yticklabels(list(label_map.values()), fontsize=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a73c01c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()) , lr = 1e-3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "570f4381",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_metric = {\n",
    "        'Train_Loss' : [] , \n",
    "        'Train_Accuracy' : [] ,\n",
    "        'Validation_Loss' : [] , \n",
    "        'Validation_Accuracy' : []\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5943b830",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "def train() : \n",
    "    for epoch in tqdm(range(EPOCHS)) : \n",
    "        # TRAIN \n",
    "        model.train()\n",
    "        train_loss , train_acc = 0.0 , 0.0 \n",
    "\n",
    "        for X , y in train_ds : \n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            optim.zero_grad()\n",
    "            logits = model(X)\n",
    "            y_preds = torch.argmax(logits , dim = 1)\n",
    "\n",
    "            loss = loss_fn(logits , y)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_acc += accuracy_fn(y_preds , y)\n",
    "\n",
    "        train_loss /= len(train_ds)\n",
    "        train_acc /= len(train_ds)\n",
    "\n",
    "        # VALIDATE\n",
    "        model.eval()\n",
    "        val_loss , val_acc = 0.0 , 0.0\n",
    "\n",
    "        with torch.inference_mode() : \n",
    "            for X , y in val_ds : \n",
    "                X, y = X.to(device), y.to(device)\n",
    "\n",
    "                logits = model(X)\n",
    "                y_preds = torch.argmax(logits , dim = 1)\n",
    "\n",
    "                val_loss += loss_fn(logits, y).item()\n",
    "                val_acc += accuracy_fn(y_preds , y)\n",
    "\n",
    "\n",
    "        val_loss /= len(val_ds)\n",
    "        val_acc /= len(val_ds)\n",
    "\n",
    "        print(\n",
    "            f\"\"\"[Epoch {epoch+1}/{EPOCHS}]\n",
    "            [Train Loss: {train_loss:0.5f}] [Train Accuracy: {train_acc:0.2f}%]\n",
    "            [Validation Loss: {val_loss:0.5f}] [Validation Accuracy: {val_acc:0.2f}%]\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "        model_metric[\"Train_Loss\"].append(train_loss)\n",
    "        model_metric[\"Train_Accuracy\"].append(train_acc)\n",
    "        model_metric[\"Validation_Loss\"].append(val_loss)\n",
    "        model_metric[\"Validation_Accuracy\"].append(val_acc)\n",
    "\n",
    "    return model_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c0bd673e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [06:20<25:22, 380.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/5]\n",
      "            [Train Loss: 0.69374] [Train Accuracy: 50.35%]\n",
      "            [Validation Loss: 0.69347] [Validation Accuracy: 49.33%]\n",
      "            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [12:35<18:52, 377.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/5]\n",
      "            [Train Loss: 0.69335] [Train Accuracy: 50.01%]\n",
      "            [Validation Loss: 0.69306] [Validation Accuracy: 50.67%]\n",
      "            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [19:32<13:10, 395.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/5]\n",
      "            [Train Loss: 0.69335] [Train Accuracy: 50.27%]\n",
      "            [Validation Loss: 0.69313] [Validation Accuracy: 50.67%]\n",
      "            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [26:07<06:35, 395.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/5]\n",
      "            [Train Loss: 0.69322] [Train Accuracy: 50.27%]\n",
      "            [Validation Loss: 0.69315] [Validation Accuracy: 49.33%]\n",
      "            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [32:30<00:00, 390.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/5]\n",
      "            [Train Loss: 0.69343] [Train Accuracy: 49.70%]\n",
      "            [Validation Loss: 0.69311] [Validation Accuracy: 50.67%]\n",
      "            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_metric = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "661df3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado\n",
    "MODEL_PATH = Path(\"../models/sentiment_lstm_model.pth\")\n",
    "torch.save(model.state_dict(), MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7052ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
