{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e381901",
   "metadata": {},
   "source": [
    "# Fine-tuning con Transformers\n",
    "Usaremos un modelo Transformer preentrenado para clasificar sentimiento binario y compararemos su desempeño y costos con la red neuronal liviana desarrollada previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c4b4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install transformers datasets accelerate evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465289a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import inspect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fa72a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = pathlib.Path(\"..\") / \"data\" / \"processed\" / \"cleaned_sentiment_data.csv\"\n",
    "MODEL_NAME = \"bert-base-uncased\"  # modelo más liviano para ajustar en GPU pequeña\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "df = pd.read_csv(DATA_PATH).dropna(subset=[\"cleaned_review\", \"sentiment\"])\n",
    "df[\"sentiment\"] = df[\"sentiment\"].astype(int)\n",
    "df[[\"cleaned_review\", \"sentiment\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d188a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, eval_df = train_test_split(\n",
    "    df[[\"cleaned_review\", \"sentiment\"]],\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=df[\"sentiment\"],\n",
    ")\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "eval_df = eval_df.reset_index(drop=True)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "eval_dataset = Dataset.from_pandas(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085e8513",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_function(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"cleaned_review\"],\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "        max_length=128,  # reducir longitud para aliviar memoria\n",
    "    )\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_eval = eval_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e4d570",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce53113",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\"__index_level_0__\"] #Eliminar columnas innecesarias si existen\n",
    "existing_cols = [c for c in cols_to_drop if c in tokenized_train.column_names]\n",
    "if existing_cols:\n",
    "    tokenized_train = tokenized_train.remove_columns(existing_cols)\n",
    "    tokenized_eval = tokenized_eval.remove_columns(existing_cols)\n",
    "\n",
    "tokenized_train = tokenized_train.rename_column(\"sentiment\", \"labels\")\n",
    "tokenized_eval = tokenized_eval.rename_column(\"sentiment\", \"labels\")\n",
    "tokenized_train.set_format(\"torch\")\n",
    "tokenized_eval.set_format(\"torch\")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16a5c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    accuracy = accuracy_metric.compute(predictions=preds, references=labels)[\"accuracy\"]\n",
    "    f1 = f1_metric.compute(predictions=preds, references=labels, average=\"weighted\")[\"f1\"]\n",
    "    return {\"accuracy\": accuracy, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5923fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.cuda.empty_cache()\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=2,\n",
    "    id2label={0: \"negativo\", 1: \"positivo\"},\n",
    "    label2id={\"negativo\": 0, \"positivo\": 1},\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "supported_training_args = set(inspect.signature(TrainingArguments.__init__).parameters)\n",
    "training_args_kwargs = {\n",
    "    \"output_dir\": \"../models/transformer-sentiment\",\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"per_device_eval_batch_size\": 8,\n",
    "    \"num_train_epochs\": 3,\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"seed\": RANDOM_STATE,\n",
    "}\n",
    "\n",
    "def set_if_supported(arg: str, value) -> bool:\n",
    "    if arg in supported_training_args:\n",
    "        training_args_kwargs[arg] = value\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "set_if_supported(\"gradient_accumulation_steps\", 2)\n",
    "set_if_supported(\"warmup_ratio\", 0.1)\n",
    "set_if_supported(\"logging_steps\", 50)\n",
    "set_if_supported(\"report_to\", \"none\")\n",
    "set_if_supported(\"fp16\", torch.cuda.is_available())\n",
    "set_if_supported(\"gradient_checkpointing\", True)\n",
    "\n",
    "has_eval_epoch = set_if_supported(\"evaluation_strategy\", \"epoch\") or set_if_supported(\"eval_strategy\", \"epoch\")\n",
    "has_save_epoch = set_if_supported(\"save_strategy\", \"epoch\")\n",
    "if not has_save_epoch:\n",
    "    set_if_supported(\"save_steps\", 500)\n",
    "\n",
    "set_if_supported(\"load_best_model_at_end\", True)\n",
    "set_if_supported(\"metric_for_best_model\", \"f1\")\n",
    "set_if_supported(\"greater_is_better\", True)\n",
    "\n",
    "if training_args_kwargs.get(\"load_best_model_at_end\", False):\n",
    "    if not (has_eval_epoch and has_save_epoch):\n",
    "        training_args_kwargs[\"load_best_model_at_end\"] = False\n",
    "\n",
    "training_args = TrainingArguments(**training_args_kwargs)\n",
    "\n",
    "trainer_kwargs = {\n",
    "    \"model\": model,\n",
    "    \"args\": training_args,\n",
    "    \"train_dataset\": tokenized_train,\n",
    "    \"eval_dataset\": tokenized_eval,\n",
    "}\n",
    "supported_trainer_args = set(inspect.signature(Trainer.__init__).parameters)\n",
    "if \"tokenizer\" in supported_trainer_args:\n",
    "    trainer_kwargs[\"tokenizer\"] = tokenizer\n",
    "if \"data_collator\" in supported_trainer_args:\n",
    "    trainer_kwargs[\"data_collator\"] = data_collator\n",
    "if \"compute_metrics\" in supported_trainer_args:\n",
    "    trainer_kwargs[\"compute_metrics\"] = compute_metrics\n",
    "\n",
    "trainer = Trainer(**trainer_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6578784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = trainer.train()\n",
    "train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaae087",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics = trainer.evaluate()\n",
    "eval_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dc4fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"../models/transformer-sentiment-best\")\n",
    "tokenizer.save_pretrained(\"../models/transformer-sentiment-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41b9f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: \"negativo\", 1: \"positivo\"}\n",
    "\n",
    "def predict_sentiment(review: str) -> dict:\n",
    "    encoded = tokenizer(\n",
    "        review,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        padding=True,\n",
    "    )\n",
    "    encoded = {k: v.to(model.device) for k, v in encoded.items()}\n",
    "    with torch.no_grad():\n",
    "        logits = model(**encoded).logits\n",
    "        probs = torch.softmax(logits, dim=-1).cpu().numpy()[0]\n",
    "    pred_label = int(np.argmax(probs))\n",
    "    return {\n",
    "        \"review\": review,\n",
    "        \"label\": label_map[pred_label],\n",
    "        \"prob_positive\": float(probs[1]),\n",
    "        \"prob_negative\": float(probs[0]),\n",
    "    }\n",
    "\n",
    "sample_prediction = predict_sentiment(\"the pacing drags but performances shine\")\n",
    "sample_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec66cce",
   "metadata": {},
   "source": [
    "## Análisis comparativo\n",
    "1. Registra `eval_metrics['eval_accuracy']` y `eval_metrics['eval_f1']` tras el fine-tuning.\n",
    "2. Contrasta esos valores contra la precisión del MLP en [notebooks/model_train_base.ipynb](notebooks/model_train_base.ipynb) para discutir mejoras en recall/F1 vs. costo computacional.\n",
    "3. Observa el tiempo por época y el uso de GPU (`nvidia-smi`) para cuantificar el sobrecosto del Transformer.\n",
    "4. Explora ejemplos donde el MLP falló y comprueba si el Transformer corrige esos casos (usa `predict_sentiment`).  \n",
    "En general, el Transformer debería capturar dependencias largas y matices léxicos que el TF-IDF+MLP ignora, a cambio de un entrenamiento más lento y mayor consumo de memoria."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
